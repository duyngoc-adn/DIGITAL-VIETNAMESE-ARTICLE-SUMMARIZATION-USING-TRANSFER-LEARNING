{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEkOub9vVMsK",
        "outputId": "470d2777-ddc5-4c34-8210-8533979996d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall dill\n",
        "!pip install dill==0.3.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "rSXmZL4qk-xj",
        "outputId": "2ed736db-9601-4472-ac08-6f754b571533"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dill 0.3.6\n",
            "Uninstalling dill-0.3.6:\n",
            "  Would remove:\n",
            "    /usr/local/bin/get_objgraph\n",
            "    /usr/local/bin/undill\n",
            "    /usr/local/lib/python3.8/dist-packages/dill-0.3.6.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/dill/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled dill-0.3.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dill==0.3.4\n",
            "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Installing collected packages: dill\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.14 requires dill>=0.3.6, but you have dill 0.3.4 which is incompatible.\n",
            "evaluate 0.4.0 requires datasets>=2.0.0, but you have datasets 1.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed dill-0.3.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dill"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVWe-Np2SrIA"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7BBg2SNEaDa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the vncorenlp python wrapper\n",
        "!pip install vncorenlp\n",
        "\n",
        "# Download VnCoreNLP-1.1.1.jar & its word segmentation component (i.e. RDRSegmenter) \n",
        "# !mkdir -p vncorenlp/models/wordsegmenter\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "# !wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "# !mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "# !mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "# !mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/\n",
        "!pip install datasets==1.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V12w92ApjA-_",
        "outputId": "3adbc9bb-7444-4d49-96fc-c0a3665e1786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vncorenlp\n",
            "  Downloading vncorenlp-1.0.3.tar.gz (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from vncorenlp) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->vncorenlp) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->vncorenlp) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->vncorenlp) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->vncorenlp) (2022.12.7)\n",
            "Building wheels for collected packages: vncorenlp\n",
            "  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-py3-none-any.whl size=2645950 sha256=d0029ce5fe9029193e45e4235840a1ca413e3beabb0057c94ea74238b220d80e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/e9/86/706911c12e307aeb9a2702399f0dad38d36f1d6f9dde8af35e\n",
            "Successfully built vncorenlp\n",
            "Installing collected packages: vncorenlp\n",
            "Successfully installed vncorenlp-1.0.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets==1.0.2\n",
            "  Downloading datasets-1.0.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (3.8.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (3.1.0)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (9.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets==1.0.2) (1.3.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.0.2) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==1.0.2) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.15.0)\n",
            "Installing collected packages: datasets\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.7.1\n",
            "    Uninstalling datasets-2.7.1:\n",
            "      Successfully uninstalled datasets-2.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "evaluate 0.4.0 requires datasets>=2.0.0, but you have datasets 1.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed datasets-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp -r gs://vietai_public/viT5/data/vietnews .\n",
        "!gsutil cp -r gs://vietai_public/viT5/data/wikilingua ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qIeBITzq6RR",
        "outputId": "358675aa-19e3-47d4-8a3a-db51d7103f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://vietai_public/viT5/data/vietnews/test.tsv...\n",
            "Copying gs://vietai_public/viT5/data/vietnews/test_dedup.tsv...\n",
            "Copying gs://vietai_public/viT5/data/vietnews/train_dedup.tsv...\n",
            "| [3 files][422.4 MiB/422.4 MiB]                                                \n",
            "Operation completed over 3 objects/422.4 MiB.                                    \n",
            "Copying gs://vietai_public/viT5/data/wikilingua/test.tsv...\n",
            "Copying gs://vietai_public/viT5/data/wikilingua/train.tsv...\n",
            "Copying gs://vietai_public/viT5/data/wikilingua/val.tsv...\n",
            "\\ [3 files][ 63.5 MiB/ 63.5 MiB]                                                \n",
            "Operation completed over 3 objects/63.5 MiB.                                     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDuUZV7nF4IL"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments, AutoModel\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ah6qWnJtF-Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a967b8-cfcf-4779-e164-966d95435960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MBartForConditionalGeneration(\n",
              "  (model): MBartModel(\n",
              "    (shared): Embedding(64001, 1024, padding_idx=1)\n",
              "    (encoder): MBartEncoder(\n",
              "      (embed_tokens): Embedding(64001, 1024, padding_idx=1)\n",
              "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): MBartDecoder(\n",
              "      (embed_tokens): Embedding(64001, 1024, padding_idx=1)\n",
              "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=64001, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\")  \n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"vinai/bartpho-word\")\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")  \n",
        "#model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\n",
        "\n",
        "\n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgIAqjmjF9UC"
      },
      "outputs": [],
      "source": [
        "def preprocess_function(examples):\n",
        "    model_inputs = tokenizer(\n",
        "        examples[\"inputs\"], max_length=1024, truncation=True, padding=True\n",
        "    )\n",
        "    \n",
        "    labels = tokenizer(\n",
        "        examples[\"labels\"], max_length=64, truncation=True, padding=True\n",
        "    )\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    model_inputs['input_ids'] = model_inputs['input_ids']\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = pd.read_excel(\"/content/drive/MyDrive/D:  /Đại học/Năm 3/Kỳ 1/Xử lí ngôn ngữ tự nhiên/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Data/data_Tuoi_Tre.xlsx\")\n",
        "#data = pd.read_excel(\"/content/drive/MyDrive/data_Tuoi_Tre.xlsx\")\n",
        "#data = pd.read_excel(\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Data/data_Tuoi_Tre.xlsx\")\n",
        "#data = pd.read_excel(\"/content/drive/MyDrive/data_Tuoi_Tre.xlsx\")\n",
        "\n",
        "train = pd.read_excel(\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Data/Data4model/train.xlsx\")\n",
        "val = pd.read_excel(\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Data/Data4model/val.xlsx\")\n",
        "test = pd.read_excel(\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Data/Data4model/test.xlsx\")"
      ],
      "metadata": {
        "id": "55ldcUQpVqis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data = data.iloc[:100, :]"
      ],
      "metadata": {
        "id": "aoMIeVC9Wala"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Obl3e6AFGzI"
      },
      "outputs": [],
      "source": [
        "input_lines = train[\"Content\"].values\n",
        "label_lines = train[\"Summary\"].values\n",
        "\n",
        "for i in range(len(input_lines)):\n",
        "  input_lines[i] = str(input_lines[i]) + '</s>'\n",
        "\n",
        "dict_obj = {'inputs': input_lines, 'labels': label_lines}\n",
        "dataset = Dataset.from_dict(dict_obj)\n",
        "train_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_lines = val[\"Content\"].values\n",
        "label_lines = val[\"Summary\"].values\n",
        "\n",
        "for i in range(len(input_lines)):\n",
        "  input_lines[i] = str(input_lines[i]) + '</s>'\n",
        "\n",
        "dict_obj = {'inputs': input_lines, 'labels': label_lines}\n",
        "dataset = Dataset.from_dict(dict_obj)\n",
        "val_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
      ],
      "metadata": {
        "id": "pOzzMUYzUnPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lines = test[\"Content\"].values\n",
        "label_lines = test[\"Summary\"].values\n",
        "\n",
        "for i in range(len(input_lines)):\n",
        "  input_lines[i] = str(input_lines[i]) + '</s>'\n",
        "\n",
        "dict_obj = {'inputs': input_lines, 'labels': label_lines}\n",
        "dataset = Dataset.from_dict(dict_obj)\n",
        "test_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)"
      ],
      "metadata": {
        "id": "oFwHgNOdUr3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHiwgkvsGfVD"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3\",\n",
        "                                      do_train=True,\n",
        "                                      do_eval=True,\n",
        "                                      num_train_epochs=3,\n",
        "                                      learning_rate=1e-4,\n",
        "                                      warmup_ratio=0.05,\n",
        "                                      weight_decay=0.01,\n",
        "                                      per_device_train_batch_size=2,\n",
        "                                      per_device_eval_batch_size=2,\n",
        "                                      logging_dir='./log',\n",
        "                                      group_by_length=True,\n",
        "                                      save_strategy=\"steps\",\n",
        "                                      save_steps= 2000,  \n",
        "                                      save_total_limit=10,\n",
        "                                      overwrite_output_dir=True,\n",
        "                                      fp16=True,\n",
        "                                      )\n",
        "# AdaFactor for ViT5-large models as it based on T5v1.1.\n",
        "# See https://medium.com/the-artificial-impostor/paper-adafactor-adaptive-learning-rates-with-sublinear-memory-cost-a543abffa37\n",
        "\n",
        "# from transformers.optimization import Adafactor, AdafactorSchedule\n",
        "# optimizer = Adafactor(\n",
        "#     model.parameters(),\n",
        "#     lr=1e-3,\n",
        "#     eps=(1e-30, 1e-3),\n",
        "#     clip_threshold=1.0,\n",
        "#     decay_rate=-0.8,\n",
        "#     beta1=None,\n",
        "#     weight_decay=0.0,\n",
        "#     relative_step=False,\n",
        "#     scale_parameter=False,\n",
        "#     warmup_init=False\n",
        "# )\n",
        "# lr_scheduler = AdafactorSchedule(optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lnrMZZJHro8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c7cbfac-5261-4eb9-8c59-d302d67226d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n",
            "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 29893\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 44841\n",
            "  Number of trainable parameters = 420361216\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14559' max='44841' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14559/44841 2:19:39 < 4:50:32, 1.74 it/s, Epoch 0.97/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.155300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.296100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.241400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.342600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.482400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.461600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.415800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.395000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>2.368200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.364100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>2.289500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>2.257400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>2.253500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>2.237400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>2.200800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8000</td>\n",
              "      <td>2.186900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8500</td>\n",
              "      <td>2.124200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9000</td>\n",
              "      <td>2.139700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9500</td>\n",
              "      <td>2.171300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10000</td>\n",
              "      <td>2.116400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10500</td>\n",
              "      <td>2.038900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11000</td>\n",
              "      <td>2.027700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11500</td>\n",
              "      <td>2.075500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12000</td>\n",
              "      <td>2.037400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12500</td>\n",
              "      <td>2.072500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13000</td>\n",
              "      <td>2.057200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13500</td>\n",
              "      <td>1.979000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14000</td>\n",
              "      <td>2.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14500</td>\n",
              "      <td>1.974000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-2000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-2000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-4000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-4000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-4000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-6000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-6000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-6000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-8000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-8000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-8000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-10000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-10000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-10000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-12000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-12000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-12000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-14000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-14000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-14000/pytorch_model.bin\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-9-8edd18974a53>\", line 11, in <module>\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\", line 1527, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/trainer.py\", line 1837, in _inner_training_loop\n",
            "    self.scaler.step(self.optimizer)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\", line 341, in step\n",
            "    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py\", line 288, in _maybe_opt_step\n",
            "    retval = optimizer.step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py\", line 68, in wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\", line 140, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/transformers/optimization.py\", line 362, in step\n",
            "    denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 1515, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 1473, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 751, in getmodule\n",
            "    f = getabsfile(module)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 720, in getabsfile\n",
            "    _filename = getsourcefile(object) or getfile(object)\n",
            "  File \"/usr/lib/python3.8/inspect.py\", line 705, in getsourcefile\n",
            "    if os.path.exists(filename):\n",
            "  File \"/usr/lib/python3.8/genericpath.py\", line 19, in exists\n",
            "    os.stat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=_traintokenized_datasets,\n",
        "    data_collator=data_collator,\n",
        "    eval_dataset= val_tokenized_datasets,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#torch.cuda.empty_cache()\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized_datasets,\n",
        "    data_collator=data_collator,\n",
        "    #optimizers=(optimizer, lr_scheduler)\n",
        ")\n",
        "trainer.train(resume_from_checkpoint=\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-40000\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930,
          "referenced_widgets": [
            "ac5551577ae345eda2ea80f1cf811543",
            "da53260d7faa48eb9fcfd1bf47e2058c",
            "1400d4fef7bb4c46bbf00ca905efe132",
            "eb1ecb2421d84dc69d953ab40b38a467",
            "b4ef35f77c3347719477f32d1338c92a",
            "d5c588a226fd4324b9233990da38cd92",
            "881ad3f6c75044e09937b166f6c779e3",
            "64d87161ea8847bea7d4c6cd4dae1bbc",
            "80dde3ec5edc453b87dbc9c72039097a",
            "8ef0a5853bc645baa41488d497abe7a6",
            "ba6ef4aa841643479cf3ba154a053387"
          ]
        },
        "id": "GIx0jk58h5Q6",
        "outputId": "eecb719f-fa3c-46e3-a611-e11cdc4ab89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n",
            "Loading model from /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-40000.\n",
            "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: token_type_ids. If token_type_ids are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 29893\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 44841\n",
            "  Number of trainable parameters = 420361216\n",
            "  Continuing training from checkpoint, will skip to saved global_step\n",
            "  Continuing training from epoch 2\n",
            "  Continuing training from global step 40000\n",
            "  Will skip the first 2 epochs then the first 10106 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10106 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac5551577ae345eda2ea80f1cf811543"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='44841' max='44841' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [44841/44841 45:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>40500</td>\n",
              "      <td>0.989300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41000</td>\n",
              "      <td>0.992000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41500</td>\n",
              "      <td>0.989100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42000</td>\n",
              "      <td>0.960100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42500</td>\n",
              "      <td>0.998300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43000</td>\n",
              "      <td>0.958700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43500</td>\n",
              "      <td>0.985900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44000</td>\n",
              "      <td>0.993400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44500</td>\n",
              "      <td>0.970300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-42000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-42000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-42000/pytorch_model.bin\n",
            "Saving model checkpoint to /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-44000\n",
            "Configuration saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-44000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-44000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=44841, training_loss=0.10606480476350641, metrics={'train_runtime': 2808.1344, 'train_samples_per_second': 31.935, 'train_steps_per_second': 15.968, 'total_flos': 1.9434603045873254e+17, 'train_loss': 0.10606480476350641, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzEWbrNMSo8c"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/temp/checkpoint-10000 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "arC47XJIgedm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHCiygFJ7RhP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "90a1bffd5a954471a3b222ca4702b5df",
            "0e5367f09b9e477d8fa04c5619dca939",
            "1f012d17e3754cbb954d2861042fcf08",
            "1c4c6048b5b74c0e92a0874988d86c6b",
            "1ec758ad922e4a868cf0372ca72aa8c4",
            "d177f24927cf49a29d2ae571da7d9790",
            "c0361a3413dc4212b320e5993f2b20df",
            "d1b72a371c664ad0883953c289131d02",
            "6dfeb52e44974e619067cfb194e6408a",
            "ee7aa82cf9dc461c946910e38b01c681",
            "d818d7e42ac74ef3a3a03a073ecc8325"
          ]
        },
        "outputId": "9ab66ca6-cc72-4b94-d015-251ee0e6a7c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90a1bffd5a954471a3b222ca4702b5df"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"rouge\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55vewVrY7UG3"
      },
      "outputs": [],
      "source": [
        "input_lines = []\n",
        "label_lines = []\n",
        "task = 'wikilingua'\n",
        "with open(f'{task}/test.tsv') as file:\n",
        "  for line in file:\n",
        "    line = line.strip().split('\\t')\n",
        "    input = line[0]\n",
        "    input_lines.append(input +'</s>')\n",
        "    label_lines.append(line[1])\n",
        "\n",
        "\n",
        "\n",
        "input_lines  = input_lines\n",
        "label_lines = label_lines\n",
        "dict_obj = {'inputs': input_lines, 'labels': label_lines}\n",
        "\n",
        "dataset = Dataset.from_dict(dict_obj)\n",
        "test_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk_hB4b-8GkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a596f59-7afb-46ee-b6f1-1cedaf5542e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MBartForConditionalGeneration(\n",
              "  (model): MBartModel(\n",
              "    (shared): Embedding(64001, 1024, padding_idx=1)\n",
              "    (encoder): MBartEncoder(\n",
              "      (embed_tokens): Embedding(64001, 1024, padding_idx=1)\n",
              "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): MBartEncoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): MBartDecoder(\n",
              "      (embed_tokens): Embedding(64001, 1024, padding_idx=1)\n",
              "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (6): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (7): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (8): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (9): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (10): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (11): MBartDecoderLayer(\n",
              "          (self_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MBartAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=64001, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/drive/MyDrive/Đồ án DS310 - Xử lí ngôn ngữ tự nhiên/Model/BARTPho-word/epoch3/checkpoint-44000\")\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/checkpoint-10000\")  \n",
        "model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54ckcdzG7Xlc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "e2012b14ca0241d3b0f8e73252eb8dc7",
            "40cb51aacf504d6fbe2dee89235b677e",
            "c25c7330768445d2ae001ca9738593ab",
            "ca470aa776ae4e77a162b8fa604c59b1",
            "eb96fecbdfff430e8bed163566f25dc9",
            "045f4919f1684fc3a84e826bef9c2fae",
            "a4be9d0ab34d4bfab6cc236195ffc266",
            "5cae5ac126194533a85710cabe217d21",
            "0dcce8aa380344e2a2fd11a155d45509",
            "3d264c46f22b4241b5816f00be1853d1",
            "723361ad896c4ebc99ecf6802225c7d6"
          ]
        },
        "outputId": "e55e53ba-8051-4274-89d3-4bd80ad43b83"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/117 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2012b14ca0241d3b0f8e73252eb8dc7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:3578: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': AggregateScore(low=Score(precision=0.6115088236707809, recall=0.5651223822690056, fmeasure=0.5746260455883623), mid=Score(precision=0.6158903243248348, recall=0.5696141528927743, fmeasure=0.5778855941592502), high=Score(precision=0.620131426294889, recall=0.5743201136546836, fmeasure=0.5814044385284818)),\n",
              " 'rougeL': AggregateScore(low=Score(precision=0.3872853138224935, recall=0.35798774283054324, fmeasure=0.3635503316187511), mid=Score(precision=0.3913958252796764, recall=0.36213203770188096, fmeasure=0.3672539776842556), high=Score(precision=0.3958727796484118, recall=0.3663990367748857, fmeasure=0.37128459333336883))}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "metrics = load_metric('rouge')\n",
        "\n",
        "max_target_length = 256\n",
        "dataloader = torch.utils.data.DataLoader(val_tokenized_datasets, collate_fn=data_collator, batch_size=32)\n",
        "\n",
        "predictions = []\n",
        "references = []\n",
        "for i, batch in enumerate(tqdm(dataloader)):\n",
        "  outputs = model.generate(\n",
        "      input_ids=batch['input_ids'].to('cuda'),\n",
        "      max_length=max_target_length,\n",
        "      attention_mask=batch['attention_mask'].to('cuda'),\n",
        "  )\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n",
        "\n",
        "    labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n",
        "    actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n",
        "  predictions.extend(outputs)\n",
        "  references.extend(actuals)\n",
        "  metrics.add_batch(predictions=outputs, references=actuals)\n",
        "\n",
        "\n",
        "metrics.compute()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXJrSJVz7cOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3963886f-7df9-49b3-9e54-b592a74aac0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rouge1\n",
            "Score(precision=0.6158903243248348, recall=0.5696141528927743, fmeasure=0.5778855941592502)\n",
            "rouge2\n",
            "Score(precision=0.27076173724492425, recall=0.25125542774791243, fmeasure=0.2545314679449651)\n",
            "rougeL\n",
            "Score(precision=0.3913532458655102, recall=0.3623553705549759, fmeasure=0.36743325780149916)\n"
          ]
        }
      ],
      "source": [
        "rouge_output = metrics.compute(predictions=predictions, references=references, rouge_types=[\"rouge1\",\"rouge2\",\"rougeL\"])\n",
        "for key,value in rouge_output.items():\n",
        "  print(key)\n",
        "  print(value.mid)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,11):  \n",
        "  print('Prediction: ',predictions[i])\n",
        "  print('Truth: ',label_lines[i])\n",
        "  print('Content: ',input_lines[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eMH4GCxK-Z2",
        "outputId": "299c6dc8-a90d-431d-df35-4eaf88a43964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction:  UBND tỉnh Bình Phước vừa có văn bản chỉ đạo các địa phương không được chủ quan, không để người dân tiếp tục đăng ký hoặc thông tin sai sự thật, gây hoang mang trong dư luận.\n",
            "Truth:  Chọn dụng cụ trực quan giúp ích cho khán giả. Dùng dụng cụ trực quan phù hợp với bài phát biểu. Cẩn trọng khi sử dụng phần mềm trình chiếu Powerpoint.\n",
            "Content:  Có nhiều lý do để bạn dùng dụng cụ trực quan. Chúng sẽ giúp cho những gì bạn đang truyền đạt trở nên dễ hiểu hơn, giúp khán giả nhớ được những gì bạn nói, thu hút những người học bằng trực quan và làm cho bài nói của bạn trở nên thuyết phục hơn. Hãy nắm rõ mục đích bạn sử dụng từng dụng cụ trực quan trong bài nói của mình. Việc sử dụng dụng cụ trực quan rất hữu ích, tuy nhiên bạn cần chọn dùng những dụng cụ phù hợp. Ví dụ, trong bài nói về kim cương ở trên, nếu muốn khán giả của mình biết về bốn tiêu chí cần xem xét khi chọn mua kim cương, bạn nên trình chiếu một biểu đồ minh họa về nơi người thợ đá quý cắt viên kim cương, hoặc có thể trình chiếu những bức ảnh về các loại kim cương trong suốt, kim cương màu trắng, màu vàng cạnh nhau để cho khán giả thấy được sự khác biệt về màu sắc. Mặt khác thì việc sử dụng một bức ảnh bên trong một cửa hàng trang sức lại không hữu ích cho lắm. Powerpoint là một phần mềm trình chiếu vô cùng hữu ích. Bạn có thể trình chiếu hình ảnh, biểu đồ, đồ thị một cách dễ dàng. Tuy nhiên có một số lỗi mà người thuyết trình thường gặp khi sử dụng Powerpoint để trình chiếu. Những lỗi này hoàn toàn có thể tránh được nếu bạn dành thời gian xem xét chúng.  Đừng viết tất cả những gì bạn muốn nói lên slide (trang trình chiếu). Chúng ta hẳn đều đã từng được nghe những bài phát biểu mà người nói chỉ chăm chú vào việc đọc slide. Điều này làm khán giả cảm thấy nhàm chán và sẽ nhanh chóng mất tập trung. Thay vào việc đọc slide, hãy sử dụng biểu đồ để giới thiệu, nhắc lại và nhấn mạnh những thông tin quan trọng. Luôn nhớ rằng slide chỉ nên đóng vai trò hỗ trợ chứ không nên là bản sao hoàn chỉnh của những gì bạn muốn nói. Đảm bảo khán giả có thể đọc được slide của bạn. Hãy sử dụng cỡ chữ mà khán giả có thể đọc được và đừng trình bày quá nhiều thứ trên một slide. Nếu khán giả không thể đọc được hay không xem được hết những gì bạn chiếu trên slide thì tất cả sẽ trở nên vô ích. Sử dụng hiệu ứng trình chiếu đơn giản. Các hình ảnh bay qua bay lại, phóng to, thu nhỏ và thay đổi màu sắc có thể thu hút, nhưng đồng thời cũng làm khán giả trở nên sao nhãng. Đừng dùng quá nhiều hiệu ứng đặc biệt. Slide của bạn chỉ nên đóng vai trò hỗ trợ chứ không nên giữ vai trò chính trong bài thuyết trình.</s>\n",
            "Prediction:  Những chiếc điện thoại di động này tuy nhỏ gọn nhưng vẫn có khả năng gây ra nhiều vấn đề về sức khỏe và khả năng vận hành tốt nếu không muốn mất kiểm tra hoặc làm việc.\n",
            "Truth:  Chọn một tư thế ngủ tự nhiên. Nằm bất động trên giường. Nhắm mắt nhẹ nhàng. Thở theo nhịp đều. Đáp lại tiếng ồn hoặc khi bị người khác làm phiền.\n",
            "Content:  Bạn hãy nằm ở tư thế ngủ tự nhiên nhất có thể. Đừng cầm gì cả, bạn chỉ cần nằm lên giường và cố gắng không ngóc đầu lên. Nếu thường nằm sấp khi ngủ thì bạn cũng nên chọn tư thế này khi giả vờ ngủ, như vậy sẽ không khiến người khác nghi ngờ. Khi ngủ thật, bạn sẽ cử động rất ít. Để người khác tin rằng bạn đang ngủ thực sự thì tốt nhất là bạn đừng động đậy. Hãy nằm thật im, trừ khi có ai đó quan sát bạn ngủ rất lâu. Bạn đừng cố nhắm chặt hai mí mắt lại với nhau. Để giả vờ ngủ giống thật nhất thì bạn cần thả lỏng các cơ, trong đó bao gồm cả mí mắt.  Hãy nhìn xuống dưới khi bạn nhắm mắt để mí mắt không động đậy. Mắt bạn không phải lúc nào cũng nhắm hoàn toàn khi ngủ, vậy nên hãy để mí mắt rủ xuống và khép lại nhẹ nhàng, bạn sẽ vẫn có thể nhìn được qua khe hở giữa chúng. Bạn hãy thở chậm, đều và sâu. Nhịp thở của bạn cần thư thái và đều nhất có thể. Với mỗi nhịp thở, bạn hãy đếm nhẩm trong đầu khi hít vào và sau đó cố gắng thở ra trong cùng khoảng thời gian như vậy. Nếu nghe thấy một tiếng động lớn hoặc có người chạm vào bạn, hãy thở một nhịp ngắn, đột ngột và khẽ cựa người. Ngay cả khi ngủ thì cơ thể chúng ta vẫn nhận thức được những gì đang diễn ra xung quanh. Hãy đáp lại những âm thanh và chuyển động trong phòng bằng những phản ứng giống như vô thức để người khác tin rằng bạn đang ngủ thật.  Sau khi đáp lại yếu tố làm phiền giấc ngủ, bạn hãy thả lỏng cơ thể và đưa hơi thể trở về trạng thái chậm và đều. Nhớ là không được mỉm cười hay mở mắt, nếu không người khác sẽ phát hiện ra là bạn đang giả vờ ngủ.</s>\n",
            "Prediction:  Ca sĩ Đàm Vĩnh Hưng cho biết đã nhận được thông báo kết thúc điều tra vụ án hình sự từ Công an tỉnh Bình Dương ngày 31-8, trong đó nêu rõ việc chuyển toàn bộ hồ sơ vụ án đến Viện Kiểm sát nhân dân cùng cấp đề nghị truy tố bị can Nguyễn Phương Hằng.\n",
            "Truth:  Tìm hiểu thành phẩm. Đậy nắp nồi và đun liu riu khoảng 15 phút. Nhấc nồi nước gia vị ra khỏi bếp. Cho cơm vào bát thủy tinh. Dọn cơm lên ăn khi vẫn còn ấm.\n",
            "Content:  Bạn có thể làm cho gạo thường có vị tương tự như gạo làm sushi bằng việc nêm đúng gia vị. Tuy nhiên, sẽ rất khó làm cho gạo thường có độ dẻo giống như gạo làm sushi. Bạn có thể dùng cơm trong phương pháp này để làm món sashimi, cơm bento và cuốn sushi nhưng sẽ rất khó để làm món nigiri. Nước sẽ ngừng sôi trong vài giây khi bạn cho gạo vào. Chờ nước và gạo sôi trở lại, sau đó giảm nhiệt và đậy kín nắp nồi. Tiếp tục đun đến khi gạo thấm hút hết nước. Đặt nồi sang một bên để làm nguội. Trong các bước tiếp theo, bạn nên tránh dùng bất kỳ vật dụng kim loại nào; nếu không, bạn sẽ gặp tình trạng giấm làm dậy mùi kim loại. Loại cơm dẻo của người Nhật chỉ ngon khi vẫn còn ấm thay vì nóng.</s>\n",
            "Prediction:  Tổ tuần tra đặc biệt 171, thuộc Công an tỉnh Bình Dương đã giảm hơn 50% so với tháng trước và chỉ có 12 vụ so với cùng kỳ năm 2021.\n",
            "Truth:  Mở ứng dụng Settings (Cài đặt). Chọn \"Wi-Fi.\" Nhấn nút Menu (⋮) và chọn \"Advanced\" (Nâng cao). Kéo xuống dưới cùng trình đơn Advanced và tìm trường \"IP address\".\n",
            "Content:  Trường này sẽ hiển thị địa chỉ IP riêng của thiết bị Android.</s>\n",
            "Prediction:  Ủy ban Xã hội đề nghị Chính phủ nghiên cứu để có cơ chế đặc thù với việc xử lý những vi phạm khi thực hiện các biện pháp cấp bách trong phòng chống dịch COVID-19.\n",
            "Truth:  Chú ý hành vi của chó. Kiểm tra gáy chó. Kiểm tra nướu chó. Kiểm tra nước tiểu của chó. Đưa chó đi khám bác sĩ thú y.\n",
            "Content:  Chó bị mất nước thường dùng sức lực còn lại để tìm nước uống. Nếu chó bị mất nước, bạn có thể nhận thấy những hành vi bất thường ở chó như bồn chồn hoặc đi tới đi lui như đang tìm nước uống.  Chó có thể liên tục liếm mép hoặc/và lo lắng biểu hiện rõ trên khuôn mặt nếu không tìm thấy đủ nước để uống.  Chó bị mất nước cũng có thể nằm và tựa mũi vào bát nước. Thử nghiệm mất nước cơ bản mà bạn thường nhìn thấy các bác sĩ thú y thực hiện tại phòng khám là kéo gáy chó lên. Thử nghiệm này có thể đo độ đàn hồi của da và da mất đi đàn hồi có thể dấu hiệu chó bị mất nước. Bạn có thể tự tiến hành thử nghiệm này bằng thực hiện các bước sau:  Xác định vị trí gáy chó. Gáy chó là vùng da rũ xuống qua vai hoặc sau cổ chó. Nâng gáy chó lên. Bạn có thể nắm vùng da này và nhẹ nhàng kéo thẳng lên 5-7 cm so với lưng chó. Thả gáy ra và quan sát. Nếu ngậm đủ nước, da sẽ quay về vị trí cũ ngay lập tức. Nếu mất nước, da sẽ trở nên kém đàn hồi và không thể quay về vị trí cũ ngay. Nếu da mất hơn 2 giây để trở lại bình thường, chó có thể đang bị mất nước. Nướu là vị trí tốt để kiểm tra tình trạng mất nước sớm ở chó. Nướu bình thường sẽ ẩm ướt và sáng bóng giống như nướu của người. Động vật mất nước thường có nướu khô hoặc hơi dính vì không tiết đủ nước bọt. Bạn nên biết chó lo lắng hay sợ hãi cũng có thể có bị khô nướu. Vì vậy, cần đảm bảo kiểm tra nướu khi chó thực sự thả lỏng để tránh nhầm lẫn. Nếu không uống đủ nước, cơ thể chó có thể tự động thực hiện các bước nhằm lưu giữ nước. Trong tình huống này, chó sẽ không đi tiểu vì bàng quang trống rỗng hoặc nước tiểu trở nên đậm đặc. Nước tiểu đậm đặc thường có màu vàng đậm.  Điều này xảy ra là do thận chó hoạt động quá sức để tái chế lại nước trong cơ thể và giữ nước.  Bạn nên lưu ý nếu chó ít đi tiểu hơn bình thường hoặc nước tiểu của chó có màu bất thường. Nếu chó có vẻ khỏe mạnh và chỉ xuất hiện dấu hiệu mất nước đơn giản như uống sạch nước trong bát, bạn có thể cho chó uống thêm nước và quan sát xem tình trạng có cải thiện không. Tuy nhiên, nếu chó mất nước có vẻ ốm hoặc tình trạng không cải thiện sau khi uống nước, bạn nên đưa chó đi khám bác sĩ thú y ngay. Một số động vật mất nước cần truyền nước qua tĩnh mạch để bảo vệ chức năng của các cơ quan nội tạng trong quá trình bù nước.</s>\n",
            "Prediction:  Ngày 19/11, tại Buôn Ma Thuột (Đắk Lắk), Ban tổ chức Lễ hội Cà phê tỉnh Đắk Lắk phối hợp với các đơn vị triển lãm cà phê phin, cà phê sữa đá quy mô lớn.\n",
            "Truth:  Tải tập tin cài đặt 4K Video Downloader. Cài đặt 4K Video Downloader. Truy cập https://www.youtube.com từ trình duyệt web. Truy cập video mà bạn muốn tải về. Sao chép địa chỉ video. Mở 4K Video Downloader. Nhấp vào Paste Link (Dán đường dẫn) ở phía trên góc trái cửa sổ 4K Video Downloader. Chọn định dạng video từ trình đơn \"Format\" (Định dạng). Chọn chất lượng. Nhấp vào Download (Tải về) ở bên dưới cửa sổ để tải video về máy tính. Mở thư mục lưu video.\n",
            "Content:  Truy cập https://www.4kdownload.com/products/product-videodownloader từ trình duyệt của máy tính, rồi nhấp vào Get 4K Video Downloader (Tải 4K Video Downloader) ở bên trái trang. Tập tin cài đặt 4K Video Downloader sẽ tải tập tin về máy tính của bạn. 4K Video Downloader sử dụng được trên máy tính Windows và Mac. Sau khi tải xong tập tin cài đặt 4K Video Downloader, bạn có thể cài đặt theo cách sau:  Windows: Nhấp đúp vào tập tin cài đặt, nhấp vào Yes khi được hỏi và thực hiện theo hướng dẫn cài đặt trên màn hình. Mac: Nhấp đúp vào tập tin cài đặt, xác minh việc cài đặt nếu cần, nhấp và kéo biểu tượng ứng dụng 4K Video Downloader về thư mục \"Applications\" (Ứng dụng) và thực hiện theo hướng dẫn trên màn hình.  Video sẽ tự động phát ngay sau đó. Nhấp vào địa chỉ video tại thanh địa chỉ ở phía trên trình duyệt của cửa sổ, rồi ấn Ctrl+A (Windows) hoặc ⌘ Command+A (Mac) để chọn tất cả và ấn Ctrl+C hoặc ⌘ Command+C để sao chép. Nếu 4K Video Downloader không tự động mở sau khi cài đặt xong, bạn nhấp vào đường dẫn trong trình đơn Start của Windows hoặc thư mục Applications (Ứng dụng) của Mac. Như vậy, 4K Video Downloader sẽ xuất nội dung đường dẫn mà bạn vừa sao chép. Nếu bạn không thấy \"4K\" trong lựa chọn chất lượng cho video có hỗ trợ định dạng này, việc thay đổi định dạng video từ MP4 sang MKV thường sẽ làm xuất hiện lựa chọn 4K. Theo mặc định, chất lượng cao nhất sẽ được chọn, nhưng bạn có thể đánh dấu vào ô bên cạnh một chất lượng khác (chẳng hạn như 1080p) nếu máy tính không hỗ trợ chất lượng cao nhất. Ví dụ, nhiều màn hình laptop không hỗ trợ video 4K, nên việc tải video với định dạng 4K là không cần thiết.  Sau khi quá trình tải video hoàn tất, bạn nhấp phải vào video và chọn Show in Folder (Hiển thị trong thư mục) trong danh sách kết quả tìm kiếm. Thao tác này sẽ mở cửa sổ File Explorer (Windows) hoặc Finder (Mac) có video đã tải về; lúc này bạn có thể nhấp đúp vào video để phát bằng chương trình mặc định của máy tính. Trên máy Mac, bạn có thể giữ phím Ctrl trong khi nhấp vào video để mở trình đơn nhấp phải.</s>\n",
            "Prediction:  Trong bối cảnh dịch bệnh COVID-19 diễn biến phức tạp, các doanh nghiệp đã tìm cách cải tiến chất lượng để thu hút đầu tư, góp phần cải thiện chất lượng sản xuất, chất lượng và các dự án phát triển nhà máy thông minh...\n",
            "Truth:  Thấm chất lỏng được chừng nào hay chừng ấy bằng tờ khăn giấy khô gập lại. Lau một mặt phẳng không thấm nước sao cho thật sạch và khô, sau đó trải trang giấy lên. Thấm ướt một tờ khăn giấy sạch và cẩn thận chấm lên vết bẩn lần nữa. Chuẩn bị dung dịch giấm pha loãng. Tẩm dung dịch giấm vào bông gòn và cẩn thận chấm lên một chữ nhỏ trong tài liệu. Chấm bông gòn lên vết bẩn. Dùng khăn giấy khô thấm lên chỗ vết bẩn đã được làm sạch và hong khô giấy.\n",
            "Content:  Nếu nước thấm ướt hết tờ khăn giấy, bạn hãy dùng một tờ khăn giấy khác thấm nốt phần còn lại. Thấm cẩn thận để hạn chế tối đa diện tích vết bẩn bằng cách không làm loang chất lỏng ra xung quanh. Cẩn thận ấn nhẹ với động tác lên xuống để khỏi làm hỏng giấy. Đảm bảo chỗ làm việc phải sạch, bằng không bạn sẽ có một vết bẩn nữa phải xử lý! Dùng các vật không thấm nước chặn lên hai góc hoặc nhiều góc của trang giấy để giảm rủi ro làm nhăn giấy. Lặp lại bước này cho đến khi bạn không còn thấy màu thấm ra khăn giấy. Với các vết bẩn gốc nước chưa bị khô, màu của vết bẩn hầu như sẽ được tẩy sạch. Nếu vết bẩn vẫn còn, bạn hãy chuyển sang bước kế tiếp. Hòa nửa cốc giấm trắng với nửa cốc nước. Các loại giấm khác có thể làm ố giấy, vì vậy bạn nhớ chỉ dùng giấm hoàn toàn không màu. Thực hiện bước này ở xa nơi đặt tờ giấy để tránh trường hợp lỡ tay làm đổ giấm lên giấy gây hư hại thêm. Kiểm tra xem liệu mực in có bị thấm lên bông gòn không. Một số phương pháp in không làm mực bị lem, nhưng cũng có trường hợp bị lem mực. Nếu gặp trường hợp sau, bạn nên chọn một phần nhỏ nhất, khó nhận thấy nhất trên giấy để thử.   Nếu mực bị phai ra thì các nỗ lực loại bỏ vết bẩn có thể làm hỏng giấy.  Nếu miếng bông gòn vẫn sạch, bạn hãy thực hiện bước tiếp theo. Giấm sẽ hòa tan mọi sắc tố còn lại và làm sạch vết bẩn. Nếu vết bẩn có diện tích rộng hoặc đậm màu, có thể bạn cần lặp lại bước này với một miếng bông mới khi miếng bông đầu tiên bị bẩn. Dùng bông mới để đảm bảo bạn không vô tình làm vết bẩn lan ra. Nếu bạn vừa xử lý một trang giấy trong sách, hãy để mở cuốn sách ở trang đó. Lót khăn giấy lên cả hai mặt tờ giấy vừa làm sạch và dùng vật nặng chặn lên.</s>\n",
            "Prediction:  Trong lúc tắm sông ở huyện Thanh Chương, Nghệ An, ba thanh niên bị đuối nước, một người được người dân cứu sống và trao giấy khen của chủ tịch UBND huyện cho ông Nguyễn Hữu Hiền.\n",
            "Truth:  Pha với tỷ lệ 2 phần xanh dương với 1 phần xanh lá. Vẽ.\n",
            "Content:  Màu ngọc lam có sắc tố xanh dương nhiều hơn xanh lá. Bạn có thể thoải mái thử nghiệm với nhiều tỷ lệ khác nhau, nhưng tỷ lệ 2:1 là tỷ lệ cơ bản.  Tỷ lệ màu xanh lá nhiều hơn một chút so với tỷ lệ cơ bản – chẳng hạn như 2:1,5 – sẽ cho ra màu ngọc lam có sắc xanh dương ánh lục đậm. Tỷ lệ xanh lá ít hơn một chút (ít hơn tỷ lệ 2:1) sẽ tạo thành màu gần như xanh dương. Cân nhắc cho thêm một chút màu vàng để có sắc độ sáng hơn. Thử pha màu vàng với màu xanh dương theo tỷ lệ 1:5 hoặc 1:6. Pha màu vàng với hỗn hợp xanh dương và xanh lá. Thêm một chút màu trắng nếu màu vừa pha có sắc độ quá đậm. Màu trắng sẽ làm màu ngọc lam nhạt bớt và dịu đi. Khi đã pha được màu ngọc lam là bạn có thể vẽ ngay. Đảm bảo màu ngọc lam phải có sắc độ đúng như bạn mong muốn. Tuy có thể vẽ bằng chiếc cọ vừa dùng để trộn màu, nhưng bạn nên cân nhắc rửa sạch cọ trước để đảm bảo độ chính xác. Nếu muốn pha thêm màu ngọc lam, bạn nhớ pha đúng tỷ lệ màu xanh dương và xanh lá như đã pha trước đó.  Nếu muốn pha thêm màu khi đã vẽ nửa chừng nhưng không pha được đúng tỷ lệ như trước, bạn hãy cân nhắc pha một lượng lớn màu có sắc độ mới, sau đó vẽ đè lên tất cả các màu ngọc lam để làm đều màu.</s>\n",
            "Prediction:  Cuộc thi viết 'Tình người lao động vì cộng đồng, vì cộng đồng, vì cộng đồng mạng có thể cùng nhau chia sẻ về nghề và vì cộng đồng'.\n",
            "Truth:  Tránh các ảnh hưởng tiêu cực. Thách thức những suy nghĩ tiêu cực. Đối phó với những chấn thương trong quá khứ. Đừng sợ thất bại.\n",
            "Content:  Con người rất dễ “lây lan cảm xúc”, có nghĩa là cảm xúc của chúng ta sẽ bị chi phối bởi cảm xúc của những người xung quanh. Hãy tránh xa hành vi xấu và sự tiêu cực để chúng không thể gây ảnh hưởng đến bạn.  Hãy khôn ngoan trong việc lựa chọn bạn bè. Những người bạn xung quanh chúng ta có thể tác động rất lớn đến quan điểm của chúng ta – cả tốt lẫn xấu. Nếu bạn bè của bạn là những người tiêu cực, hãy cân nhắc việc chia sẻ quá trình trở nên tích cực của bản thân với họ. Khuyến khích họ tìm cách để họ cũng có thể trở nên tích cực như bạn. Nếu họ vẫn muốn duy trì sự tiêu cực của mình, bạn có thể sẽ cần phải tránh xa khỏi họ vì lợi ích của bản thân. Chỉ nên thực hiện những điều khiến bạn cảm thấy thoải mái. Nếu không thoải mái khi phải thực hiện một việc nào đó, bạn sẽ cảm thấy tồi tệ, có lỗi, hoặc lo lắng về việc thực hiện nó. Và điều đó sẽ không giúp bạn trở nên tích cực. Việc học cách nói \"không\" khi bạn không muốn làm một việc nào đó có thể giúp bạn cảm thấy mạnh mẽ hơn và thoải mái hơn về chính mình. Điều này hoàn toàn đúng đối với bạn bè hoặc người thân yêu của bạn hoặc trong môi trường làm việc. Thật dễ dàng để chúng ta bị cuốn vào thói quen suy nghĩ tiêu cực một cách “tự động”, đặc biệt là về bản thân mình. Chúng ta có thể trở thành nhà phê bình khó tính nhất của chính mình. Mỗi khi bạn gặp phải một suy nghĩ tiêu cực nào đó, hãy dành thời gian để thách thức nó. Hãy cố gắng biến nó thành suy nghĩ tích cực, hoặc tìm kiếm lỗ hổng hợp lý bên trong nó. Nếu bạn thường xuyên thực hiện biện pháp này, nó có thể trở thành thói quen, và tạo nên sự khác biệt rõ rệt trong việc cải thiện kỹ năng suy nghĩ tích cực của bạn. Hãy nói \"Tôi có thể!\" nhiều hơn là \"Tôi không thể!\". Bạn cần phải nhớ rằng, mọi việc đều có thể trở nên tích cực; hãy cố gắng nỗ lực không ngừng để thực hiện điều này.  Ví dụ, nếu bạn tức giận và nổi cáu với một người bạn, bản năng của bạn sẽ khiến bạn nghĩ rằng “Mình là một kẻ tồi tệ”. Đây là sự xuyên tạc trong nhận thức: nó đưa ra một lời tuyên bố chung về một sự việc cụ thể. Nó chỉ đem lại cảm giác tội lỗi cho bạn và không hình thành bất kỳ điều gì mà bạn có thể sử dụng để học hỏi. Thay vì vậy, hãy nhìn nhận trách nhiệm cho hành động của mình và cân nhắc xem bạn cần phải làm gì để sửa chữa nó. Ví dụ: “Mình nổi cáu với người bạn của mình, chắc chắn cô ấy sẽ bị tổn thương. Mình đã sai. Mình sẽ xin lỗi cô ấy, và lần sau, mình sẽ yêu cầu được nghỉ ngơi trong giây lát khi bàn luận về một vấn đề căng thẳng nào đó”. Cách suy nghĩ này không nhìn nhận bản thân bạn là một kẻ “tồi tệ”, nhưng là một người đã phạm lỗi và biết rút ra bài học và phát triển bản thân từ lỗi lầm của mình. Nếu bạn nhận thấy rằng bạn thường xuyên có những suy nghĩ tiêu cực về bản thân (hoặc về người khác), hãy hình thành thói quen tìm kiếm ba điều tích cực về bản thân mình khi nói về một điều tiêu cực. Ví dụ, nếu bạn nghĩ rằng mình “ngốc nghếch”, hãy bù đắp bằng ba suy nghĩ tích cực: “Mình nghĩ rằng mình là một kẻ ngốc nghếch. Nhưng tuần trước mình đã hoàn thành dự án lớn đó và nhận được những lời khen ngợi. Mình đã giải quyết nhiều vấn đề khó khăn trong quá khứ. Mình có khả năng và mình chỉ đang phải trải qua một khoảng thời gian khó khăn”. Ngay cả khi không nhận được điều mà chúng ta muốn, chúng ta cũng đã có được những kinh nghiệm quý giá. Kinh nghiệm thường đáng giá hơn vật chất. Vật chất dần dần sẽ hao mòn; kinh nghiệm mới là những gì còn đọng lại và phát triển trong suốt cuộc đời của chúng ta. Mỗi tình huống đều có những khía cạnh tích cực và tiêu cực riêng của nó. Chúng ta được phép lựa chọn khía cạnh mà chúng ta muốn tập trung chú ý. Mỗi khi bắt gặp những suy nghĩ tiêu cực, chúng ta có thể cố gắng suy nghĩ theo hướng ngược lại. Không có lý do gì khiến bạn phải lo lắng về những điều tiêu cực nếu bạn không thể thay đổi nó. Cuộc sống \"không công bằng\". Đó là bởi vì cuộc sống \"là như vậy\". Nếu lãng phí thời gian và cảm giác hạnh phúc vào những điều mà chúng ta không thể thay đổi, chúng ta sẽ dễ nản lòng. Nếu bạn nhận thấy rằng bạn thường xuyên cảm thấy không vui, buồn bã, hoặc tiêu cực, có thể bạn đang gặp phải những vấn đề tìm ẩn cần phải được xử lý. Hãy tìm kiếm sự giúp đỡ từ các chuyên gia để giúp bạn giải quyết chấn thương tâm lý, chẳng hạn như bị ngược đãi, gặp nhiều căng thẳng, thiên tai, đau buồn, và mất mát.  Tìm chuyên gia tâm lý được cấp phép, đặc biệt là những người chuyên điều trị chấn thương tâm lý. Điều trị chấn thương tâm lý với chuyên viên tư vấn hoặc nhà trị liệu có thể khá khó khăn, thậm chí đau đớn, nhưng bạn sẽ dần trở nên mạnh mẽ và tích cực hơn. Tương tự như câu nói của Franklin D. Roosevelt, điều duy nhất mà chúng ta nên sợ hãi chính là bản thân mình. Chúng ta sẽ vấp ngã và phạm phải sai lầm. Nhưng cách mà chúng ta đứng lên mới chính là điều quan trọng. Nếu chúng ta mong chờ thành công và không sợ gặp phải thất bại, chúng ta sẽ có cơ hội trở nên tích cực trong mọi hoàn cảnh.</s>\n",
            "Prediction:  Các nhà khảo cổ học tại Liên bang Nga đã tìm thấy xác của trùm phát xít Hitler trong hầm ngầm ở Berlin ngày 30-4-1945, có thể là dấu vết của ông trùm đầu tiên sử dụng để giải mã bí mật của Hitler.\n",
            "Truth:  Xì mũi đúng cách. Nghỉ ngơi thoải mái. Đi ngủ. Tránh sự kích thích không cần thiết. Uống nhiều chất lỏng. Tránh các loại hoa quả họ cam quýt. Điều chỉnh nhiệt độ phòng. Xoa dịu làn da bị nứt nẻ. Tránh đi máy bay. Tránh stress. Không uống rượu. Không hút thuốc. Ăn thực phẩm bổ dưỡng. Tập thể dục. Ngăn ngừa tái nhiễm và lây lan virus. Cứ để cho bệnh cảm diễn ra theo tự nhiên.\n",
            "Content:  Để xì mũi, bạn cần bịt một bên lỗ mũi và xì lỗ mũi bên kia vào khăn giấy. Xì nhẹ nhàng. Khi bị cảm cúm, bạn cần xì mũi thường xuyên để tống dịch nhầy ra khỏi cơ thể. Không xì mũi quá mạnh vì dịch nhầy có thể bị đẩy vào ống tai hoặc vào sâu trong các xoang. Bạn không nên đi làm hoặc đi học khi bị cảm cúm để tránh lây truyền bệnh. Bạn cũng có thể tận dụng cơ hội để nằm trên giường và tập trung vào việc làm sao cho khỏe hơn. Mặc bộ đồ ngủ vào và thư giãn. Cơ thể bạn cần được nghỉ ngơi để hồi phục, và bạn cần giải tỏa căng thẳng để giúp cơ thể có đủ năng lượng chữa bệnh. Nếu mỗi ngày ngủ ít hơn năm hoặc sáu tiếng, bạn có nguy cơ mắc bệnh cảm cúm cao gấp bốn lần. Cơ thể thực sự cần thời gian để nghỉ ngơi và hồi phục nhờ giấc ngủ, đặc biệt là khi đang chống chọi với bệnh cảm cúm. Vì thế, hãy chuẩn bị gối êm, chăn ấm, nhắm mắt lại và thả mình vào những giấc mơ.  Đắp nhiều lớp chăn khi ngủ nếu thân nhiệt của bạn dao động để có thể bỏ bớt hoặc đắp thêm chăn khi thấy nóng hoặc lạnh. Bạn có thể cần thêm gối để kê cao đầu giúp giảm ho và tránh chảy dịch mũi sau. Đặt hộp khăn giấy và sọt rác hoặc túi đựng rác cạnh giường. Như thế bạn có thể xì mũi và vứt bỏ khăn giấy khi cần. Máy tính và các trò chơi game có thể rất kích thích nhờ ánh sáng, âm thanh và nhiều thông tin mà bạn cần xử lý. Những thiết bị này làm bạn tỉnh táo và khó dỗ giấc ngủ. Dùng thiết bị điện tử và thậm chí cả đọc sách có thể góp phần làm căng mắt hoặc đau đầu – điều mà bạn chẳng muốn chút nào khi đã sẵn mệt mỏi vì ốm. Cơ thể bạn sản sinh ra nhiều dịch nhầy khi bị cảm cúm. Dịch nhầy đòi hỏi nhiều chất lỏng. Chất lỏng được nạp thêm vào cơ thể sẽ làm loãng dịch nhầy, do đó bạn có thể tống ra dễ dàng hơn. Giới hạn lượng caffeine nạp vào khi bị cảm vì caffeine thực sự có thể khiến cơ thể khô kiệt. Chất a-xít trong các loại nước quả như nước cam có thể khiến bạn ho nhiều hơn. Nó có thể kích ứng cổ họng vốn đã nhạy cảm. Bạn nên tìm cách khác để bù nước và uống thêm vitamin C. Bạn cần căn phòng ấm áp nhưng không nóng. Khi bạn nóng hoặc lạnh, cơ thể bạn sẽ tiêu hao năng lượng để cố gắng làm ấm lên hoặc mát đi. Vì vậy khi bị cảm, bạn không nên để quá lạnh hoặc quá nóng. Cơ thể bạn cần tập trung chống chọi với virus chứ không phải để điều hòa thân nhiệt. Da trên mũi có thể bị kích ứng khi bạn bị cảm. Đó là do bạn xì mũi nhiều. Một chút dầu khoáng petroleum jelly bôi vào dưới mũi hoặc khăn giấy có chất dưỡng ẩm có thể giúp ích. Khi bị cảm, tốt nhất là bạn không đi máy bay. Việc thay đổi áp suất có thể làm tổn hại màng nhĩ khi bạn bị nghẹt mũi. Dùng thuốc thông mũi và thuốc xịt dung dịch muối nếu buộc phải đi máy bay. Nhai kẹo cao su cũng giúp ích khi ngồi trên máy bay. Stress tăng rủi ro nhiễm cảm cúm và khiến bệnh lâu khỏi hơn. Hormone gây stress làm hệ miễn dịch suy yếu và không thể đẩy lùi căn bệnh. Hãy tránh xa các tình huống gây căng thẳng, tập thiền và hít thở sâu. Tuy một chút rượu có thể giúp bạn dễ ngủ, nhưng quá nhiều sẽ khiến cơ thể mất nước. Nó còn có thể làm nặng thêm các triệu chứng và gây nghẹt mũi. Alcohol không tốt cho hệ miễn dịch và có thể tương tác với các loại thuốc không kê toa. Khói thuốc lá không tốt cho hệ hô hấp. Nó sẽ khiến tình trạng nghẹt mũi và ho nặng hơn và kéo dài hơn. Hút thuốc còn gây tổn hại cho phổi, và do đó khó lành bệnh hơn. Dù đang ốm, bạn vẫn cần năng lượng và dinh dưỡng để giúp cơ thể khỏe lại. Hãy ăn với thực đơn ít béo, nhiều chất xơ với hoa quả và rau, ngũ cốc nguyên hạt và protein. Dùng các thức ăn giàu vitamin C, thức ăn có thể mở thông các xoang và làm tan dịch nhầy như ớt, mù tạt và cải ngựa. Chắc bạn đã biết là tập thể dục giúp cơ thể khỏe khoắn, nhưng hơn thế nữa nó còn giúp bạn mau lành bệnh. Nếu bị cảm, việc tập thể dục có lẽ là tốt. Tuy nhiên, khi bị sốt cao, cảm thấy rất đau hoặc yếu mệt thì bạn nên nghỉ ngơi. Giảm cường độ hoặc ngừng chương trình tập luyện nếu nó khiến bệnh cảm cúm nặng thêm. Hãy ở nhà chống chọi với cảm cúm và tránh ở gần người khác. Đảm bảo che miệng khi ho hoặc hắt xì, cố gắng dùng mặt trong khuỷu tay che miệng thay cho bàn tay. Bạn cũng cần rửa tay nhiều lần hoặc dùng nước rửa tay. Các triệu chứng của căn bệnh là cách để cơ thể loại trừ virus. Chẳng hạn như các cơn sốt giúp tiêu diệt virus và cho phép các protein chống virus trong máu lưu thông tốt hơn. Vì thế, việc không dùng thuốc hoặc các phương pháp giảm các cơn sốt vừa phải trong vài ngày có thể giúp bạn mau khỏi hơn.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"0\""
      ],
      "metadata": {
        "id": "vuxvP3qF1rOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"\n",
        "Chương trình hành động của Chính phủ đã đề ra 33 nhiệm vụ tập trung vào 5 nhóm nhiệm vụ giải pháp, trước hết là nhóm nhiệm vụ nâng cao, thống nhất nhận thức về đặc thù của đô thị, vai trò, vị thế của đô thị trong sự phát triển chung. Trong đó, xác định phát triển đô thị gồm 3 trụ cột chính là quy hoạch, xây dựng và quản lý đô thị.\n",
        "\"Quy hoạch phải đi trước một bước với tư duy đột phá, tầm nhìn chiến lược. Quy hoạch lúng túng, chậm chạp, không được đầu tư ngang tầm thì lãng phí nguồn lực, phát triển không bền vững, phát triển không đột phá. Công tác quy hoạch làm tốt thì mới tiết kiệm được nguồn lực, xác định và phát huy được tiềm năng khác biệt, cơ hội nổi trội, lợi thế cạnh tranh, chỉ ra và hóa giải những khó khăn, thách thức của địa phương, của vùng”, Thủ tướng phân tích.\n",
        "Theo Thủ tướng, quy hoạch tổng thể nhưng thực hiện có thể phân kỳ phù hợp với nguồn lực; có thể kiên trì thực hiện trong 5 năm, 10 năm, 20 năm, thậm chí hàng trăm năm… và nếu tôn trọng, làm theo quy hoạch hoàn chỉnh thì sẽ có một đô thị trật tự và phát triển.\n",
        "Ngoài ra cần đầu tư phát triển hệ thống hạ tầng đô thị đồng bộ, hiện đại trên cơ sở huy động mạnh mẽ các nguồn lực, có cơ chế, chính sách để huy động nguồn lực, kết hợp hài hòa, hợp lý, hiệu quả giữa nguồn lực bên trong và bên ngoài, giữa nguồn lực Nhà nước với các nguồn lực xã hội; đồng thời tiết kiệm, tăng thu, giảm chi, phân bổ và sử dụng nguồn lực hiệu quả, đầu tư có trọng tâm, trọng điểm.\n",
        "“Hiện vẫn còn nhiều vướng mắc về thể chế, cơ chế, chính sách cần xử lý nhưng với cơ chế đang có thì các địa phương vẫn có thể làm được nếu lãnh đạo các bộ, ngành, địa phương tập trung suy nghĩ, vận dụng tối đa các quy định hiện có trên tinh thần dám nghĩ, dám làm\", Thủ tướng lưu ý.\n",
        "Bùi Thạc Chuyên cho biết gặp áp lực khi chuyển thể văn học từ các tác phẩm của Nguyễn Ngọc Tư. Theo anh, truyện của nữ nhà văn thường có lối viết ngắn nhưng giàu tính gợi mở, các nhân vật có số phận, chứa đựng nội tâm và tiếng nói mạnh mẽ. Do đó, ngoài yếu tố sáng tạo, anh cố gắng để giữ lại những gì mình tâm đắc trong truyện gốc. \n",
        "Tro tàn rực rỡ có sự tham gia của Phương Anh Đào, Lê Công Hoàng, Bảo Ngọc Doling, Ngô Quang Tuấn, Hạnh Thúy… Phim là câu chuyện của ba phụ nữ với 3 số phận khác nhau, cách họ sống với niềm vui, nỗi ẩn ức và ngọn lửa tình yêu với chính những người đàn ông của đời mình. Bối cảnh của chuyện xảy ra ở xóm Thơm Rơm, Cà Mau với nhiều chất liệu điện ảnh và văn hóa.\n",
        "Chia sẻ với VietNamNet, Phương Anh Đào cho biết đây là vai diễn thử thách lớn nhất trong sự nghiệp diễn xuất. Trong phim, diễn viên đảm nhận vai Nhàn - một trong 3 nữ chính. Nhàn có số phận tréo ngoe, luôn khao khát yêu và được yêu đến cháy bỏng. Vốn được biết đến với nét đẹp hiện đại, song nữ diễn viên đã “lột xác” ấn tượng với vai diễn người phụ nữ khắc khổ, tảo tần trong phim.\n",
        "“Tôi thay đổi hình ảnh rất nhiều cho vai diễn với mong muốn mang đến một Phương Anh Đào khác trên màn ảnh. Thay vì những cảnh bầm dập thể xác, nhân vật của tôi chứa nhiều thương tổn tinh thần. Mọi cảm xúc đều được giữ ở bên trong, và nó khiến nhiều người suy ngẫm. Đó cũng là cách kể chuyện của nhân vật mà anh Bùi Thạc Chuyên muốn hướng đến trong phim”, cô chia sẻ. \n",
        "Phim ghi nhận điểm sáng với diễn xuất của các diễn viên. Họ lột tả được nhân vật của mình khi bị đẩy vào hoàn cảnh cùng cực và cách thích nghi một cách bị động trước cuộc đời gần như không lối thoát. \n",
        "Hai diễn viên nam Lê Công Hoàng và Quang Tuấn thể hiện tròn vai giữa bối cảnh câu chuyện hầu hết đều xoay quanh những người đàn bà. Diễn viên Quang Tuấn tiết chế được biểu cảm cường điệu so với các vai diễn trước đây. Anh khắc họa một gã đàn ông đau đớn mất con gái và nỗi ám ảnh thường trực vì ánh sáng rực rỡ của những ngọn lửa được đốt lên từ chính ngôi nhà mình. Nam diễn viên diễn chừng mực, không lên gân hay gào thét để người xem tự thấu cảm về nỗi đau cùng cực.\n",
        "\"Do quá nhập vai, tôi đã tự lấy bật lửa đốt tay mình và đến giờ vẫn còn để lại vết bỏng\", anh kể. Trước ngày phim bấm máy, nam diễn viên dành một tháng để đến set quay, học nghề ở các lò than gần một tháng để đảm bảo hóa thân tốt. \n",
        "\"\"\"\n",
        "\n",
        "text =  sentence + \" </s>\"\n",
        "encoding = tokenizer(text, return_tensors=\"pt\")\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(\"cuda\"), encoding[\"attention_mask\"].to(\"cuda\")\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=256,\n",
        "    early_stopping=False)\n",
        "for output in outputs:\n",
        "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    print(line)"
      ],
      "metadata": {
        "id": "lTQ_1p9_L3uo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "4e6ff318-ea06-432a-d7a1-05bb219c7218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-77ff71eda898>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msentence\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" </s>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m outputs = model.generate(\n\u001b[1;32m     20\u001b[0m     \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_masks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qg5-fFuHORNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac5551577ae345eda2ea80f1cf811543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da53260d7faa48eb9fcfd1bf47e2058c",
              "IPY_MODEL_1400d4fef7bb4c46bbf00ca905efe132",
              "IPY_MODEL_eb1ecb2421d84dc69d953ab40b38a467"
            ],
            "layout": "IPY_MODEL_b4ef35f77c3347719477f32d1338c92a"
          }
        },
        "da53260d7faa48eb9fcfd1bf47e2058c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5c588a226fd4324b9233990da38cd92",
            "placeholder": "​",
            "style": "IPY_MODEL_881ad3f6c75044e09937b166f6c779e3",
            "value": "Skipping the first batches: 100%"
          }
        },
        "1400d4fef7bb4c46bbf00ca905efe132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64d87161ea8847bea7d4c6cd4dae1bbc",
            "max": 10106,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80dde3ec5edc453b87dbc9c72039097a",
            "value": 10106
          }
        },
        "eb1ecb2421d84dc69d953ab40b38a467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ef0a5853bc645baa41488d497abe7a6",
            "placeholder": "​",
            "style": "IPY_MODEL_ba6ef4aa841643479cf3ba154a053387",
            "value": " 10106/10106 [00:51&lt;00:00, 305.34it/s]"
          }
        },
        "b4ef35f77c3347719477f32d1338c92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5c588a226fd4324b9233990da38cd92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "881ad3f6c75044e09937b166f6c779e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64d87161ea8847bea7d4c6cd4dae1bbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80dde3ec5edc453b87dbc9c72039097a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ef0a5853bc645baa41488d497abe7a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6ef4aa841643479cf3ba154a053387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90a1bffd5a954471a3b222ca4702b5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e5367f09b9e477d8fa04c5619dca939",
              "IPY_MODEL_1f012d17e3754cbb954d2861042fcf08",
              "IPY_MODEL_1c4c6048b5b74c0e92a0874988d86c6b"
            ],
            "layout": "IPY_MODEL_1ec758ad922e4a868cf0372ca72aa8c4"
          }
        },
        "0e5367f09b9e477d8fa04c5619dca939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d177f24927cf49a29d2ae571da7d9790",
            "placeholder": "​",
            "style": "IPY_MODEL_c0361a3413dc4212b320e5993f2b20df",
            "value": "Downloading: "
          }
        },
        "1f012d17e3754cbb954d2861042fcf08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1b72a371c664ad0883953c289131d02",
            "max": 1656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6dfeb52e44974e619067cfb194e6408a",
            "value": 1656
          }
        },
        "1c4c6048b5b74c0e92a0874988d86c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee7aa82cf9dc461c946910e38b01c681",
            "placeholder": "​",
            "style": "IPY_MODEL_d818d7e42ac74ef3a3a03a073ecc8325",
            "value": " 4.20k/? [00:00&lt;00:00, 186kB/s]"
          }
        },
        "1ec758ad922e4a868cf0372ca72aa8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d177f24927cf49a29d2ae571da7d9790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0361a3413dc4212b320e5993f2b20df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1b72a371c664ad0883953c289131d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dfeb52e44974e619067cfb194e6408a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee7aa82cf9dc461c946910e38b01c681": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d818d7e42ac74ef3a3a03a073ecc8325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2012b14ca0241d3b0f8e73252eb8dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40cb51aacf504d6fbe2dee89235b677e",
              "IPY_MODEL_c25c7330768445d2ae001ca9738593ab",
              "IPY_MODEL_ca470aa776ae4e77a162b8fa604c59b1"
            ],
            "layout": "IPY_MODEL_eb96fecbdfff430e8bed163566f25dc9"
          }
        },
        "40cb51aacf504d6fbe2dee89235b677e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045f4919f1684fc3a84e826bef9c2fae",
            "placeholder": "​",
            "style": "IPY_MODEL_a4be9d0ab34d4bfab6cc236195ffc266",
            "value": "100%"
          }
        },
        "c25c7330768445d2ae001ca9738593ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cae5ac126194533a85710cabe217d21",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dcce8aa380344e2a2fd11a155d45509",
            "value": 117
          }
        },
        "ca470aa776ae4e77a162b8fa604c59b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d264c46f22b4241b5816f00be1853d1",
            "placeholder": "​",
            "style": "IPY_MODEL_723361ad896c4ebc99ecf6802225c7d6",
            "value": " 117/117 [11:16&lt;00:00,  5.42s/it]"
          }
        },
        "eb96fecbdfff430e8bed163566f25dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045f4919f1684fc3a84e826bef9c2fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4be9d0ab34d4bfab6cc236195ffc266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cae5ac126194533a85710cabe217d21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dcce8aa380344e2a2fd11a155d45509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d264c46f22b4241b5816f00be1853d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "723361ad896c4ebc99ecf6802225c7d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}